{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murcha1990/ML_AI24/blob/main/Hometasks/Base/AI_HW3_Classification_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "125eAde1VB9p"
      },
      "source": [
        "# **Домашнее задание 3. Линейная классификация. Работа с признаками**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mza-ytI_VB9t"
      },
      "source": [
        "### **Оценивание и штрафы**\n",
        "\n",
        "Кака всегда - каждая из задач имеет «стоимость» (указана в скобках около задачи).\n",
        "\n",
        "В задании три части:\n",
        "\n",
        "- Часть 1 (2.5 балла): написание логистической регрессии своими руками\n",
        "- Часть 2 (5 баллов): различные методы отбора признаков\n",
        "- Часть 3 (3.5 балла): обучение моделей классификации на текстах\n",
        "\n",
        "Всего за задание можно получить 11 баллов, но:\n",
        "\n",
        "**Балл за задание = min{ваш балл, 10}.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-16T18:11:48.202066Z",
          "start_time": "2019-10-16T18:11:46.362572Z"
        },
        "id": "QQo0z9ZGVB9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e8b949-2024-4e02-bf5c-56c68f48db64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9L36HLHVB9w"
      },
      "source": [
        "# **Часть 1. Логистическая регрессия своими руками (2.5 балла)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-12T07:36:04.765536Z",
          "start_time": "2018-10-12T07:35:57.814973Z"
        },
        "id": "_rilRoZZVB9w"
      },
      "source": [
        "## **Задание 1. Реализуйте класс логистической регрессии, обучаемой с помощью:**\n",
        "\n",
        "**Задание 1.1 (1 балл). Градиентного спуска**\n",
        "\n",
        "**Задание 1.2 (1 балл). Стохастического градиентного спуска**\n",
        "\n",
        "До этого вы писали код без ограничений. Здесь же необходимо соблюдать следующие условия:\n",
        "\n",
        "- Градиентный спуск необходимо записать в векторном виде;\n",
        "- Циклы средствами python допускается использовать только для итераций градиентного спуска;\n",
        "\n",
        "**Класс градиентного спуска должен:**\n",
        "- В качестве критерия останова использовать (одновременно):\n",
        "  - проверку на евклидову норму разности весов на двух соседних итерациях задаваемого параметром `tolerance`;\n",
        "  - достижение максимального числа итераций, задаваемого параметром `max_iter`.\n",
        "- Обладать атрибутом `loss_history`. В нём после вызова метода fit должны содержаться значения функции потерь для всех итераций, начиная с первой (до совершения первого шага по антиградиенту). Данный атрибут необходим, чтобы проследить, что оптимизационный процесс действительно сходится;\n",
        "- Инициализировать веса случайным образом или нулевым вектором (на ваш выбор)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0hcxIOiVB9w"
      },
      "source": [
        "Полезно [почитать](https://scikit-learn.org/stable/developers/develop.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шаблон класса описан ниже, вам нужно реализовать каждую из заготовленных функций.**\n",
        "\n",
        "**ВАЖНО!** Мы заполняем данный шаблон, даже если он нам не нравится. Менять структуру класса и писать по-своему запрещено - за это будут сняты баллы."
      ],
      "metadata": {
        "id": "SgzMXEhzXEkI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-10-16T18:11:50.932537Z",
          "start_time": "2019-10-16T18:11:50.752839Z"
        },
        "id": "jPtVGuYxVB9w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class LogReg(BaseEstimator):\n",
        "    def __init__(self, gd_type='stochastic',\n",
        "                 tolerance=1e-4, max_iter=1000, w0=None, eta=1e-2):\n",
        "        \"\"\"\n",
        "        gd_type: 'full' or 'stochastic'\n",
        "        tolerance: for stopping gradient descent\n",
        "        max_iter: maximum number of steps in gradient descent\n",
        "        w0: np.array of shape (d) — init weights\n",
        "        eta: learning rate\n",
        "        \"\"\"\n",
        "        self.gd_type = gd_type\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iter = max_iter\n",
        "        self.w0 = w0\n",
        "        self.w = None\n",
        "        self.eta = eta\n",
        "        self.loss_history = None # list of loss function values at each training iteration\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (ell, d)\n",
        "        y: np.array of shape (ell)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        self.loss_history = []\n",
        "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        return self\n",
        "\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        pass\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        pass\n",
        "\n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (ell, d) (ell can be equal to 1 if stochastic)\n",
        "        y: np.array of shape (ell)\n",
        "        ---\n",
        "        output: np.array of shape (d)\n",
        "        \"\"\"\n",
        "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        pass\n",
        "\n",
        "    def calc_loss(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (ell, d)\n",
        "        y: np.array of shape (ell)\n",
        "        ---\n",
        "        output: float\n",
        "        \"\"\"\n",
        "        #╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь проверим работу вашего класса на синтетических данных."
      ],
      "metadata": {
        "id": "T5IcgSNW4bUp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQpLZkqxVB9x",
        "outputId": "fdbdb600-ec96-4f7e-81dd-7016f0cad622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOnxyTS7VB9y"
      },
      "outputs": [],
      "source": [
        "X, y = make_classification(\n",
        "    n_samples=100000, n_features=20, n_informative=10, n_redundant=10,\n",
        "    random_state=42)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvXYeHFgVB9y"
      },
      "source": [
        "**Важно:** далее предполагается, что вы используете собственную реализацию логистической регрессии.\n",
        "Если с написанием класса возникли проблемы, используйте реализацию sklearn, чтобы не терять баллы за остальные задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2b-BcRdVB9y"
      },
      "source": [
        "## **Задание 2 (0.5 балла)**\n",
        "\n",
        "Обучите логистическую регрессию на синтетических данных.\n",
        "\n",
        "На тестовой части посчитайте ROC-AUC, PR-AUC. Постройте ROC и PR кривые. Проинтерпретируйте результат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-11T20:39:43.088969Z",
          "start_time": "2018-10-11T20:39:43.084985Z"
        },
        "id": "xZ2whMm3VB9y"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55nqATc2VB91"
      },
      "source": [
        "# **Часть 2. Отбор признаков (5 баллов)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VshBXGNVVB91"
      },
      "source": [
        "Перейдём к еще одной важной части процесса работы с данными — отбору признаков. Он нужен в следующих случаях:\n",
        "- Мы хотим сократить время вычислений;\n",
        "- Мы хотим избежать переобучения;\n",
        "- Мы хотим попытаться улучшить качество модели за счет уменьшения признакового пространства;\n",
        "\n",
        "В этой части мы попробуем применить несколько подходов для отбора признаков и оценим, как они влияют на качество модели и сколько времени занимают."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Данные** \\\n",
        "\n",
        "Будем использовать датасет [об обращениях клиентов по страховым случаям](https://www.kaggle.com/competitions/porto-seguro-safe-driver-prediction/data?select=train.csv). Скачайте его с Kaggle (файл `train.csv`).\n",
        "\n",
        "Задача представляет собой бинарную классификациюю — воспользуется ли клиент страховкой на авто в ближайший год."
      ],
      "metadata": {
        "id": "bgUaF15SsO63"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-12T07:36:04.765536Z",
          "start_time": "2018-10-12T07:35:57.814973Z"
        },
        "id": "nR3Wje-lVB92"
      },
      "outputs": [],
      "source": [
        "PATH_TO_DATASET = ...\n",
        "\n",
        "data = pd.read_csv(PATH_TO_DATASET, index_col=0)\n",
        "target = data.target.values\n",
        "\n",
        "data = data.drop('target', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=124)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftJ4Ii1UVB92"
      },
      "source": [
        "### **Задание 3. (0.25 балла)**\n",
        "\n",
        "Прежде всего — в данных много категориальных признаков.\n",
        "\n",
        "- Закодируйте их с помощью one-hot кодирования. Категориальные признаки отмечены постфиксом `cat`;\n",
        "- Исходные колонки с категориальными признаками удалите;\n",
        "- Зафиксируйте, сколько признаков получилось;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6R_Nk-3VB92"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7-48mjhVB92"
      },
      "source": [
        "### **Задание 4 (1 балл)**\n",
        "\n",
        "Обучим несколько моделей, перечисленных ниже. В качестве метрики будем использовать ROC-AUC.\n",
        "\n",
        "**Задание 4.1**\n",
        "\n",
        "- Обучите модель логистической регрессии. Замерьте скорость обучения модели\n",
        "- Обучите метод опорных векторов\n",
        "- Обучите метод k ближайших соседей\n",
        "- Посчитайте качество моделей (ROC-AUC) на тестовой выборке\n",
        "\n",
        "**Задание 4.2**\n",
        "\n",
        "Для каждой из трех моделей (логистическая регрессия, SVM, KNN) подберите при помощи GridSearchCV на тренировочных данных оптимальные гиперпараметры:\n",
        "- Для логистической регрессии: C, class_weight\n",
        "- Для SVM: C, kernel, class_weight\n",
        "- Для KNN: n_neighbors, weights\n",
        "\n",
        "Затем посчитайте качество моделей на тестовой выборке.\n",
        "\n",
        "В заданиях 4.1 и 4.2 замеряйте время обучения моделей.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u4Cs3wUVB93"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ekzi8vNVB93"
      },
      "source": [
        "### **Встроенные методы**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXdGExm7VB93"
      },
      "source": [
        "**Заметим, что:**\n",
        "\n",
        "- Время обучения моделей отличается между собой.\n",
        "- Несмотря на то, что признаков много, качество модели не очень хорошее.\n",
        "\n",
        "\n",
        "Попробуем решить проблемы — улучшить качество и при этом сократить пространство признаков и, соответственно, время обучения моделей.\n",
        "\n",
        "\n",
        "\n",
        "**Отбор признаков встроеным методом.**\n",
        "\n",
        "Начнём с отбора признаков с помощью линейной модели. Делая это, мы используем факт:\n",
        "> веса линейной модели отражают  вклад каждого признака в предсказание модели, а значит, модуль этого вклада можно интерпретировать как важность признаков.\n",
        "\n",
        "Такой метод отбора называются встроенным в модель методом, так как он заложен в особенности модели.\n",
        "\n",
        "**Важно:** применение этого подхода требует машстабирования признаков (подумайте, почему). Вы можете использовать приведение к стандартному нормальному распределению (`StandardScaler`) с параметрами или MinMax преобразование (`MinMaxScaler`)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Задание 5 (0.75 балла)**\n",
        "\n",
        "Оставьте 150 признаков с наибольшими по модулю весами после обучения логистической регрессии.\n",
        "\n",
        "- Замерьте скорость такого отбора признаков. (0.2 балла)\n",
        "\n",
        "- Обучите логистическую регрессию на исходных признаках. Из них оставьте 150 лучших (с наибольшими по модулю весами).\n",
        "- Масштабируйте данные — все, кроме категориальных и бинарных признаков. Зафиксируйте, сколько признаков пришлось масштабировать. (0.25 балла)\n",
        "- Обучите новую модель на 150 признаках и оцените её качество. (0.15 балла)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WaAxJIb1jOSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "fE_KAYwaksYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Бонус (0.25 балла)**\n",
        "\n",
        "Попробуйте реализовать итеративный отбор признаков, а именно:\n",
        "\n",
        "1) Сначала отобрать около 200 признаков (действуя как в задании выше)\n",
        "\n",
        "2) Потом повторить процедуру для отбора 150 признаков из 200 (снова действуя как в задании выше)"
      ],
      "metadata": {
        "id": "xxprB-TBwY_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "E05nP4FTwp48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pclhy3j0VB94"
      },
      "source": [
        "### **Задание 6 (0.5 балла)**\n",
        "\n",
        "Также можно задать отбор признаков, используя другия свойства модели. Вспомним, что L1-регуляризация тоже умеет отбирать признаки.\n",
        "\n",
        "- Обучите модель на исходных данных. Подберите по сетке (GridSearch) наилучшее значение коэффициента регуляризации C. (0.1 балла)\n",
        "\n",
        "- Посмотрите сколько признаков отобрала модель с найденным оптимальным C?\n",
        "  - Сначала посчитайте только число ненулевых весов\n",
        "  - Затем посчитайте число весов, которые после округления до двух знаков после запятой не равны нулю (0.25 балла)\n",
        "\n",
        "Удалось ли отобрать 150 признаков за 1 шаг? (0.05 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMSiW_veVB95"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNw0lRCKVB95"
      },
      "source": [
        "### **Методы фильтрации**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPiS20_LVB95"
      },
      "source": [
        "Также можно отбирать признаки, применяя методы математической статистики. А именно, в нашем случае, через подсчёт некоторой функции для каждого признака. На основании значений этой функции (она называется *статистикой*) мы можем оставлять наиболее важные признаки. Методы этого семейства называют *фильтрационными* или *filter methods*.\n",
        "\n",
        "**Что проверяем:**\n",
        "\n",
        "Равны ли математические ожидания (то есть выборочные средние) распределений признака для двух разных классов? Если они различаются, значит и сами распределения разные. И можно сделать вывод, что по этому признаку модель сможет отличить один класс от другого. А если распределения неотличимы и значение статистики маленькое, то и признак бесполезен.\n",
        "\n",
        "\n",
        "Для проверки будем считать t-статистику:\n",
        "\n",
        "$$t(x) = \\frac{|\\mu_+ - \\mu_-|}{\\sqrt{\\frac{n_+ s^2_+ + n_- s^2_-}{n_+ + n_-}}},$$\n",
        "\n",
        "где $\\mu$, $s$, $n$ соответственно среднее, среднеквадратичное отклонение и количество объектов каждого из классов.\n",
        "\n",
        "**Примечание:** Если у вас была данная тема на курсе по математической статистике, то вы без труда узнаете статистику гипотезы о разности средних при неизвестных дисперсиях.\n",
        "\n",
        "Хотя мы и не используем статистическое тестирование явно, предпосылки о том, что наблюдения независимы, одинаково распределены и $n$ велико, должны соблюдаться, иначе статистика не имеет смысла. Но у нас большая выборка, поэтому они выполняются.\n",
        "\n",
        "Для отбора признаков по t-статистике мы возьмём признаки с наибольшим значением статистики."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Задание 7 (1 балла)**\n",
        "\n",
        "-  Масштабируйте признаки исходного датасета — все, кроме категориальных и бинарных.\n",
        "- Выделите непрерывные признаки (те, которые масштабировали)\n",
        "- Посчитайте значения t-статистики. Оставьте ***половину*** признаков с наибольшим значением статистики, объедините их с категориальными и бинарными.\n",
        "- Обучите модель логистической регрессии и замерьте качество.\n",
        "\n",
        "Не забудьте замерить скорость отбора признаков в этом случаев."
      ],
      "metadata": {
        "id": "9pLgc8i1p11H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "n_ECsmnPC_A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7lqIMZ_VB96"
      },
      "source": [
        "### **Методы-обёртки**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIFhhYqJVB96"
      },
      "source": [
        "### **Задание 8 (бонус, 1 балл)**\n",
        "\n",
        "\n",
        "Заключительный из рассматриваемых нами методов работает следующим образом: мы исключаем по очереди каждый из признаков и смотрим, как это влияет на качество модели, обученной без удаленного признака. Удаляем признаки таким жадным способом.\n",
        "\n",
        "Заметим, что нельзя оценивать качество по тестовой выборке, иначе мы можем переобучиться, как, например, при настройке гиперпараметров. Разделите выборку на 2 части, на одной из них обучайте модель без одного из признаков,  на второй части оценивайте качество. Исходную тестовую выборку стоит использовать только на финальной оценке качества.\n",
        "\n",
        "Сделайте одну итерацию и прикиньте, сколько времени займёт такой отбор признаков. Кажется, что чересчур много. Давайте возьмём маленький сэмпл данных (например, в 10 тысяч объектов), что сильно уменьшит время итерации. Теперь это долго, но уже приемлимо.\n",
        "\n",
        "Если это всё ещё долго для вашего комьютера, можете попробовать брать не по одному признаку, а сразу по пять (и удалять сразу тоже по 5). Для этого перед каждой итерацией удаления делите заново все признаки на группы по 5 штук.\n",
        "\n",
        "Снова оставьте только 150 признаков и оцените качество на тестовой выборке. Сколько времени занял такой отбор признаков?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcr82NfpVB96"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D80Fpqm5VB96"
      },
      "source": [
        "Опционально (это не оценивается) можете рассмотреть более интересные стратегии отбора, чем жадная. Например, генетические алгоритмы. Можно закодировать бинарным вектором, включаем мы или нет тот или иной признак в модель. А дальше генетическим алгоритмом оптимизировать этот вектор. Всё ещё не быстро, но точно быстрее жадного.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ6cK9jTVB96"
      },
      "source": [
        "### **Задание 9 (0.25 балла)**\n",
        "\n",
        "Подведите итоги по отбору признаков. Назовите преимущества и недостатки каждого из методов. Какой метод привёл к наилучшему качеству? Если не делали бонус — сравните встроенный метод и метод фильтрации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YGJsC_WVB96"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZ0ZI7v1VB9z"
      },
      "source": [
        "# **Часть 3. Обучение моделей на текстовых данных. (3.5 балла)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-11T20:41:54.913436Z",
          "start_time": "2018-10-11T20:41:54.907515Z"
        },
        "id": "KBWjsPSSVB9z"
      },
      "source": [
        " ### **Подготовка данных из реального мира.**\n",
        "\n",
        "Загрузите данные с конкурса  [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/competitions/nlp-getting-started/data?select=train.csv) (вам нужна только обучающая выборка, файл `train.csv`). Задача состоит в определении постов, сообщающих о чрезвычайной ситуации. В рамках домашнего задания, этот набор данных будет отличным полем для тренировки в обработке признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-10-12T07:36:04.765536Z",
          "start_time": "2018-10-12T07:35:57.814973Z"
        },
        "id": "UF_dt9lcVB90"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "PATH = ...\n",
        "data = pd.read_csv(PATH)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Задание 10. Базовая предобработка (0.5 баллов).**\n",
        "\n",
        "- Выведите на экран информацию о пропусках в данных. Если пропуски присутствуют заполните их пустой строкой."
      ],
      "metadata": {
        "id": "3REJEAhnPEAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "x9AF0Ns6PPxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Проанализируйте количество уникальных значений в числовых столбцах. Сделайте выводы."
      ],
      "metadata": {
        "id": "Nh1tdl-EPorP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "uLjxpt7bPnST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Проанализируйте соотношение классов в целевой переменной. Почему значимо это учитывать?"
      ],
      "metadata": {
        "id": "U0C59BsSQU3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "STjfzgq9Qecn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Объедините все три текстовых столбца в один (вам поможет конкатенация строк)"
      ],
      "metadata": {
        "id": "A7xePrWCPfEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "ESR7etPOQw0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Наконец, поделите данные на тренировочную и тестовую выборки."
      ],
      "metadata": {
        "id": "syMOkjGcSA3z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "pRuY5gu2O00y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxmJha91VB90"
      },
      "source": [
        "### **Задание 11. Базовые модели. (1 балл).**\n",
        "\n",
        "Данные, собираемые с сайтов, часто содержат мусор не информативный для моделей. Посмотрите, какого качества данные здесь. Для этого:\n",
        "- Примените CountVectorizer из sklearn к сырым даным. Какого размера получилась матрица?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcWyCKFFVB90"
      },
      "outputs": [],
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Обучите логистическую регрессию на полученном наборе. Какое качество `f1` у модели получилось на тестовых данных?"
      ],
      "metadata": {
        "id": "i6qBosrkWO1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "mLacyuMLV5DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Обучите SVC на тех же данных с гиперпараметрами по умолчанию. Измерьте качество (`f1`) на тестовых данных и опишите результат. Проанализируйте качество и скорость обучения."
      ],
      "metadata": {
        "id": "v7DrpPhVaHUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "9rpSS46UadkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Задание 12. Улучшение базовых моделей за счет данных. (0.5 балла).**"
      ],
      "metadata": {
        "id": "01Pjk6sVawv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Подберите гиперпараметры CountVectorizer так, чтобы признаков было минимум в 4 раза меньше, чем объектов, а качество модели при этом изменилось не более чем на $\\pm 0.07$. Опишите подобранные гиперпараметры и на что они влияют (0.5 балла).\n",
        "\n",
        "Обучайте и логистическую регрессию, и SVC."
      ],
      "metadata": {
        "id": "7OwA5U3lVD2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "9SxcCaksUSSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Задание 13. Улучшение базовых моделей путем подбора гиперпараметров. (1 балл).**\n",
        "- Попробуйте подбирать разные гиперпараметры для логистической регрессии. Опишите подбираемые гиперапарметры и ваши результаты (0.5 балла)"
      ],
      "metadata": {
        "id": "AGTy5d7Vc-O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "EJNZOPy1dZQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Попробуйте подбирать разные гиперпараметры для модели SVC. Опишите подбираемые гиперапарметры и ваши результаты (0.5 балла)"
      ],
      "metadata": {
        "id": "q8TY3Js6dchY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "NzpJ0zP_db19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ваши выводы здесь."
      ],
      "metadata": {
        "id": "WyBkbucodifU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Задание 14. (0.5 балла)**\n",
        "\n",
        "Оформите два пайплайна:\n",
        "- для модели регрессии\n",
        "- для SVC модели\n",
        "\n",
        "в пайплайн должны входить предобработка сырого датасета и обучение модели."
      ],
      "metadata": {
        "id": "ix0MxY8Td2uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ],
      "metadata": {
        "id": "l-nOCtW75uBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Выводы**\n",
        "\n",
        "Зафиксируйте выводы работы. Проанализируйте, что проделано и какие результаты вы получили. Заполняется в свободной форме."
      ],
      "metadata": {
        "id": "mnmwn355E0R2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hvcj0FmaFTmo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}